{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n!pip install -q datasets bitsandbytes einops wandb\n!pip install huggingface_hub\n\nimport torch\nimport time\nfrom huggingface_hub import notebook_login\nfrom datasets import load_dataset\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer, GenerationConfig\nfrom peft import LoraConfig, get_peft_model, PeftConfig, PeftModel, prepare_model_for_kbit_training\nfrom transformers import TrainingArguments\nfrom trl import SFTTrainer\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:39:55.480822Z","iopub.execute_input":"2025-01-14T16:39:55.481127Z","iopub.status.idle":"2025-01-14T16:40:43.160730Z","shell.execute_reply.started":"2025-01-14T16:39:55.481105Z","shell.execute_reply":"2025-01-14T16:40:43.160094Z"}},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:41:01.688204Z","iopub.execute_input":"2025-01-14T16:41:01.688510Z","iopub.status.idle":"2025-01-14T16:41:01.706881Z","shell.execute_reply.started":"2025-01-14T16:41:01.688488Z","shell.execute_reply":"2025-01-14T16:41:01.705984Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1d19465bc8d4f77b3b28af27b589945"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"dataset_name = \"Cynaptics/persona-chat\"\ndata = load_dataset(dataset_name)\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:41:20.607379Z","iopub.execute_input":"2025-01-14T16:41:20.607696Z","iopub.status.idle":"2025-01-14T16:41:22.253986Z","shell.execute_reply.started":"2025-01-14T16:41:20.607667Z","shell.execute_reply":"2025-01-14T16:41:22.253317Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19dddc47e46d4bbe88a0f8d0886bb5c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/11.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"182aa174d7604af381968be18b4614d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc12ad0ed4dd4e459a0e8c878f28c438"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['conv_id', 'persona_b', 'dialogue', 'reference', '__index_level_0__'],\n        num_rows: 20000\n    })\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"model_name = \"vilsonrodrigues/falcon-7b-instruct-sharded\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)\nmodel.config.use_cache = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:41:22.255047Z","iopub.execute_input":"2025-01-14T16:41:22.255315Z","iopub.status.idle":"2025-01-14T16:46:12.978520Z","shell.execute_reply.started":"2025-01-14T16:41:22.255292Z","shell.execute_reply":"2025-01-14T16:46:12.977639Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5679bea93934bd9a9c2b4625ffbfaca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_falcon.py:   0%|          | 0.00/6.70k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82f89770db504d3bb4d28501e5ec8fbb"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/vilsonrodrigues/falcon-7b-instruct-sharded:\n- configuration_falcon.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_falcon.py:   0%|          | 0.00/56.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d01c64cd18d4c4ab57008a18493176c"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/vilsonrodrigues/falcon-7b-instruct-sharded:\n- modeling_falcon.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82dca6efb5934794818460f46bec324d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4527800843b24702b84f0f1a44127ff5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00015.safetensors:   0%|          | 0.00/1.68G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a78fe887c3554f2f86bc7f2f024190ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2369766a12ea4c2b803e8c30ec940686"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aba8dc611b17436e974c7006756b4bf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48867e6df30f42d1a0c110c88e0f766f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a190410ed25a4791837fd625620463a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4cf8459433a4b44a8be6c55d53eb1e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"496a739bd7314197bdd3c102bd535982"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00008-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a9d043883724ee6b35eb3c364c98ab2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00009-of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8785945e3f04297a23e825612979e27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00010-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c1514e71b7c4e6faaf52476649164eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00011-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97999111317141b6aa93502b2b139267"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00012-of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b3eea0d2e3e420289014abc22d601cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00013-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b30cbe458e44df39dc82788e555af34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00014-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e258327c1a134f2991c82fac1d449e0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00015-of-00015.safetensors:   0%|          | 0.00/828M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76834c90ac534a479b3ce3f529e2863f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"582f4e93bbda48799af92c5cdcb17373"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4992d7bcb1594a70bfcee011b4c14980"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:46:12.979972Z","iopub.execute_input":"2025-01-14T16:46:12.980241Z","iopub.status.idle":"2025-01-14T16:46:14.022899Z","shell.execute_reply.started":"2025-01-14T16:46:12.980210Z","shell.execute_reply":"2025-01-14T16:46:14.022256Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a30c683d2e9c41d78828e879be46e9cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b52d07f75f747c3a88ccdd3a5ec9216"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ddc6b3c8e324e22af5321704d968594"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"#LoRA \nmodel = prepare_model_for_kbit_training(model)\n\nlora_alpha = 32 \nlora_dropout = 0.05 \nlora_rank = 32 \n\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_rank,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\n        \"query_key_value\",\n        \"dense\",\n        \"dense_h_to_4h\",\n        \"dense_4h_to_h\",\n    ]\n)\n\npeft_model = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:46:14.023970Z","iopub.execute_input":"2025-01-14T16:46:14.024305Z","iopub.status.idle":"2025-01-14T16:46:14.953517Z","shell.execute_reply.started":"2025-01-14T16:46:14.024268Z","shell.execute_reply":"2025-01-14T16:46:14.952817Z"}},"outputs":[{"name":"stderr","text":"You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#\noutput_dir = \"fine_tuned_falcon7b_dialogue\"\nper_device_train_batch_size = 16 \ngradient_accumulation_steps = 4\noptim = \"paged_adamw_32bit\"\nsave_steps = 10\nlogging_steps = 10\nlearning_rate = 2e-4\nmax_grad_norm = 0.3\nmax_steps = 180 \nwarmup_ratio = 0.03\nlr_scheduler_type = \"cosine\" \n\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    fp16=True,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=True,\n    lr_scheduler_type=lr_scheduler_type,\n    push_to_hub=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:46:14.954387Z","iopub.execute_input":"2025-01-14T16:46:14.954675Z","iopub.status.idle":"2025-01-14T16:46:14.989541Z","shell.execute_reply.started":"2025-01-14T16:46:14.954652Z","shell.execute_reply":"2025-01-14T16:46:14.988936Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#preprocess\nfrom datasets import load_dataset, Dataset\ndataset = load_dataset(\"Cynaptics/persona-chat\")\n\ndef preprocess(row):\n    \n    persona_b = \" \".join(row[\"persona_b\"])\n    dialogue = \" \".join(row[\"dialogue\"])\n\n    prompt = f\"Persona: {persona_b}\"\n    instruction = f\"Dialogue: {dialogue}\"\n\n    return {\n        \"text\": f\"{prompt}\\n\\n{instruction}\\n\\n{row['reference']}\"\n    }\n\nprocessed_data = [preprocess(row) for row in dataset[\"train\"]]\n\ntrain_dataset = Dataset.from_list(processed_data)\n\ndef tokenize_function(examples):\n    return tokenizer(\n        examples[\"text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=256,\n    )\n\nprocessed_data = [preprocess(row) for row in dataset[\"train\"]]\n\nfrom datasets import Dataset\ntrain_dataset = Dataset.from_list(processed_data)\n\ntokenized_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:46:14.990242Z","iopub.execute_input":"2025-01-14T16:46:14.990511Z","iopub.status.idle":"2025-01-14T16:46:29.910525Z","shell.execute_reply.started":"2025-01-14T16:46:14.990490Z","shell.execute_reply":"2025-01-14T16:46:29.909850Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1321060ec7a04b3b952cd396797de7d5"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:46:29.912093Z","iopub.execute_input":"2025-01-14T16:46:29.912303Z","iopub.status.idle":"2025-01-14T16:46:29.916761Z","shell.execute_reply.started":"2025-01-14T16:46:29.912285Z","shell.execute_reply":"2025-01-14T16:46:29.916074Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 20000\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"train_dataset['text'][:4]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:46:29.917686Z","iopub.execute_input":"2025-01-14T16:46:29.917877Z","iopub.status.idle":"2025-01-14T16:46:29.973395Z","shell.execute_reply.started":"2025-01-14T16:46:29.917860Z","shell.execute_reply":"2025-01-14T16:46:29.972362Z"},"_kg_hide-output":false},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['Persona: I would love to try the local food with my friend. i am quiet but confident. I love to watch movies with my dad on a rainy day. i try to limit how much i eat. I just finished practicing my bass guitar in the lifeguard station.\\n\\nDialogue: Persona A: Hey there! Persona B: What\\'s your name? Persona A: My name is William. Persona B: Nice to meet you Gavin. What kind of movies do you like to watch? Persona A: I like to watch movies that make me feel something. I like to be able to relate to the characters and feel their emotions. Persona B: I can relate to that. I like to watch movies that make me think about things in a different way. Persona A: That\\'s a good way to put it. I like to be challenged by movies. Persona B: What are some of your favorite movies? Persona A: I have a lot of favorite movies, but some of my favorites include \"The Shawshank Redemption,\" \"The Godfather,\" and \"The Lord of the Rings.\" Persona B: Those are all great movies! I love \"The Shawshank Redemption\" too. It\\'s one of my favorites. Persona A: It\\'s so well-made and has such a great story. I love it when movies can make you feel so many different emotions. Persona B: Me too. I think that\\'s what makes a great movie. Persona A: I agree. So what do you like to do for fun? Persona B: I like to spend time with my family and friends. I also like to read, watch movies, and go to the gym. Persona A: Sounds like you have a lot of interests. I like to spend time with my friends and family too. I also like to play the bass guitar. Persona B: That\\'s cool! I\\'ve always wanted to learn how to play the bass guitar. Persona A: No problem! It was nice talking to you.\\n\\nI might just do that. Thanks for the suggestion!',\n \"Persona: I am most proud of my ability to connect with nature and animals. I have never been arrested, but my stories might make you think otherwise. i love family time. my parents both are school teachers. I'm afraid of being in a situation where I can't communicate with my wife.\\n\\nDialogue: Persona A: I run every morning before work, it helps me to relieve stress. Persona B: I can see how that would help:,I do much hiking and camping; it helps me to clear my heade's up with nature. Persona A: That sounds like a lot of fun and I've always wanted to go camping! Persona B: It is really great and you should definitely try it sometime. Persona A: I will, as to my dogs - it would be lovely. Persona B: I bet he would. Also, we have dogs and his love goes camping with me Persona A: What kind of dog do you have?\\n\\nI have a Golden Retriever named Buddy.\",\n \"Persona: I enjoy my family and do not care about socializing. i m bored with my current lifestyle. i currently suffer from social anxiety. I exercise three times a week to maintain a healthy lifestyle. I'm looking for a home with a large closet so I can have plenty of space for my sewing supplies.\\n\\nDialogue: Persona A: Hey, not too much but I am just working on some pottery. Persona B: That sounds cool - I have never tried pottery before! Persona A: It is really fun! I love to make things with my hands. Persona B: I know what you mean, but it is always fun to sew. Persona A: That's awesome! I used to sew a lot when younger. Persona B: I like to make clothes for my family. Persona A: That is a great hobby Do you sell it? Persona B: No, I do it just for fun. Persona A: That's cool, and I am more into making functional things like bowled vases. Persona B: I have a lot of clothes that my family needs to sew. Persona A: That sounds like a lot of work! Persona B: It is, but I like it. Persona A: I am glad that you are enjoying your hobby! Persona B: Thank you! Persona A: Thats what it says. Persona B: Do you have any other hobbies? Persona A: I like to go out on a social way for eating and hanging with my friends. Persona B: That sounds fun, I'm more of homebody. Persona A: I can be too, but sometimes i like to get out and explore. Persona B: I like to explore new places, but don't always enjoy being around a lot of people. Persona A: I understand that :I like to go places where there aren't as many people.\\n\\nThat's my kind of place!\",\n \"Persona: I will continue to play music with my friends to help relieve stress and enjoy myself. I try to keep in touch with my family, but I can be busy with school and my job. i enjoy cooking but not baking. i can speak arabic , english , and french. My biggest fear is that I will work myself up so much that I will become ill.\\n\\nDialogue: Persona A: I'm from Japan, so my plans are moving soon to the US and it is a little nervous but exciting! Persona B: I'm from the US but speak Arabic, English and French. Where are you? Persona A: I want to be a musician, and play drums and love punk rock.I'm going working as doorman in an old club where they play the nightly pop rock Persona B: That is great! What are your dreams? Persona A: Thanks! I am nervous about my family not accepting me if they tell them that to say is gay, but will try and inform them. Persona B: I play music with my friends to help relieve stress and relax, so...I am glad that you are living up the dreams! Persona A: Hope you're right and thanks for meeting me : it is nice to meet!\\n\\nIt was nice to meet you too! Good luck with your move and music career!!\"]"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#SFTTrainer\ntrainer = SFTTrainer(\n    model=peft_model,\n    train_dataset=tokenized_dataset,\n    peft_config=peft_config,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:46:29.974506Z","iopub.execute_input":"2025-01-14T16:46:29.975247Z","iopub.status.idle":"2025-01-14T16:46:30.631552Z","shell.execute_reply.started":"2025-01-14T16:46:29.975206Z","shell.execute_reply":"2025-01-14T16:46:30.630696Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#stable training\nfor name, module in trainer.model.named_modules():\n    if \"norm\" in name:\n        module = module.to(torch.bfloat16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:46:30.632328Z","iopub.execute_input":"2025-01-14T16:46:30.632550Z","iopub.status.idle":"2025-01-14T16:46:30.641940Z","shell.execute_reply.started":"2025-01-14T16:46:30.632530Z","shell.execute_reply":"2025-01-14T16:46:30.641284Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from accelerate import Accelerator\naccelerator = Accelerator()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T12:40:06.699927Z","iopub.execute_input":"2025-01-14T12:40:06.700204Z","iopub.status.idle":"2025-01-14T12:40:06.704849Z","shell.execute_reply.started":"2025-01-14T12:40:06.700178Z","shell.execute_reply":"2025-01-14T12:40:06.704116Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"api_key\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T12:40:06.705633Z","iopub.execute_input":"2025-01-14T12:40:06.705912Z","iopub.status.idle":"2025-01-14T12:40:13.587302Z","shell.execute_reply.started":"2025-01-14T12:40:06.705886Z","shell.execute_reply":"2025-01-14T12:40:13.586609Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maniyati-mishra\u001b[0m (\u001b[33maniyati-mishra-iit-indore\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"peft_model.config.use_cache = False\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T12:40:13.588210Z","iopub.execute_input":"2025-01-14T12:40:13.588892Z","iopub.status.idle":"2025-01-14T15:37:36.984710Z","shell.execute_reply.started":"2025-01-14T12:40:13.588866Z","shell.execute_reply":"2025-01-14T15:37:36.983816Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250114_124018-e0gezek2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/aniyati-mishra-iit-indore/huggingface/runs/e0gezek2' target=\"_blank\">fine_tuned_falcon7b_dialogue</a></strong> to <a href='https://wandb.ai/aniyati-mishra-iit-indore/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/aniyati-mishra-iit-indore/huggingface' target=\"_blank\">https://wandb.ai/aniyati-mishra-iit-indore/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/aniyati-mishra-iit-indore/huggingface/runs/e0gezek2' target=\"_blank\">https://wandb.ai/aniyati-mishra-iit-indore/huggingface/runs/e0gezek2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [180/180 2:56:06, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.111500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.754400</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.635800</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.571400</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.520200</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.483600</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.445200</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.428300</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.382200</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.381400</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.357400</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.356600</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.347000</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.311000</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.308300</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.305900</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.292600</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.304300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=180, training_loss=1.460938655005561, metrics={'train_runtime': 10624.4536, 'train_samples_per_second': 1.084, 'train_steps_per_second': 0.017, 'total_flos': 1.1840467016613888e+17, 'train_loss': 1.460938655005561, 'epoch': 0.576})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:37:36.985754Z","iopub.execute_input":"2025-01-14T15:37:36.986171Z","iopub.status.idle":"2025-01-14T15:37:40.744069Z","shell.execute_reply.started":"2025-01-14T15:37:36.986134Z","shell.execute_reply":"2025-01-14T15:37:40.743362Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/niyatimishra/fine_tuned_falcon7b_dialogue/commit/668ac81a1d82b003246ef3bba537cc0685214bbe', commit_message='End of training', commit_description='', oid='668ac81a1d82b003246ef3bba537cc0685214bbe', pr_url=None, repo_url=RepoUrl('https://huggingface.co/niyatimishra/fine_tuned_falcon7b_dialogue', endpoint='https://huggingface.co', repo_type='model', repo_id='niyatimishra/fine_tuned_falcon7b_dialogue'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"#loading model\nPEFT_MODEL = \"niyatimishra/fine_tuned_falcon7b_dialogue\"\nconfig = PeftConfig.from_pretrained(PEFT_MODEL)\npeft_base_model = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    return_dict=True,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)\n\npeft_model = PeftModel.from_pretrained(peft_base_model, PEFT_MODEL)\n\npeft_tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\npeft_tokenizer.pad_token = peft_tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:47:17.065620Z","iopub.execute_input":"2025-01-14T16:47:17.065944Z","iopub.status.idle":"2025-01-14T16:49:18.796757Z","shell.execute_reply.started":"2025-01-14T16:47:17.065915Z","shell.execute_reply":"2025-01-14T16:49:18.796059Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/813 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"399ed4acf2e54df4b54d9b2782b002fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98c98b0154e64fed99a44841de7a2aea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbb1f7dddc6c47549b911547528ffd18"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"prompt = f\"\"\"\nPerson B has the following Persona information.\n\nPersona of Person B: My name is David and I'm a 35 year old math teacher.\nPersona of Person B: I like to hike and spend time in the nature.\nPersona of Person B: I'm married with two kids.\n\nInstruct: Person A and Person B are now having a conversation. \nFollowing the conversation below, write a response that Person B would say based on the\nabove Persona information. \nPlease carefully consider the flow and context of the conversation below, and use the Person B's Persona information appropriately to generate a response that you think is \nthe most appropriate reply for Person B.\n\nPersona A: Morning! I think I saw you at the parent meeting, what is your name?\n\nOutput:\n\"\"\"\n\n#tokenize\ninputs = peft_tokenizer(\n    prompt, \n    return_tensors=\"pt\", \n    truncation=True, \n    padding=True  \n)\n\ninput_ids = inputs[\"input_ids\"].cuda()\nattention_mask = inputs[\"attention_mask\"].cuda()\n#print(\"hello 2\")\n\n#inference\nwith torch.inference_mode():\n    outputs = peft_model.generate(\n        input_ids=input_ids,\n        attention_mask=attention_mask,  \n        max_new_tokens=50,\n        do_sample=True,\n        top_p=0.1,\n        temperature=0.7,\n        pad_token_id=peft_tokenizer.pad_token_id,  \n    )\n#print(\"hello 1\")\n\ndecoded_outputs = peft_tokenizer.batch_decode(outputs, skip_special_tokens=True)\noutput = decoded_outputs[0][len(prompt):]\nprint(\"Generated Output:\\n\", output)\n#print(\"hello\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:49:18.797760Z","iopub.execute_input":"2025-01-14T16:49:18.797971Z","iopub.status.idle":"2025-01-14T16:49:24.723041Z","shell.execute_reply.started":"2025-01-14T16:49:18.797953Z","shell.execute_reply":"2025-01-14T16:49:24.722193Z"}},"outputs":[{"name":"stdout","text":"Generated Output:\n \nMy name is David, it is nice to meet you! Persona B: It is nice to meet you too! Persona A: What do you like to do for fun?\n\nI like to hike and spend time in nature.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"prompt = f\"\"\"  \nPerson B has the following Persona information.  \n\nPersona of Person B: My name is Sarah, and I'm a 28-year-old software developer.  \nPersona of Person B: I love reading science fiction novels and exploring new technologies.  \nPersona of Person B: I recently adopted a rescue dog named Luna.  \n\nInstruct: Person A and Person B are now having a conversation.  \nFollowing the conversation below, write a response that Person B would say based on the  \nabove Persona information.  \nPlease carefully consider the flow and context of the conversation below, and use Person B's Persona information appropriately to generate a response that you think is  \nthe most appropriate reply for Person B.  \n\nPersona A: Hey, Sarah! What’s been keeping you busy these days?  \n\nOutput:  \n\"\"\"\n\ninputs = peft_tokenizer(\n    prompt, \n    return_tensors=\"pt\", \n    truncation=True, \n    padding=True  \n)\n\ninput_ids = inputs[\"input_ids\"].cuda()\nattention_mask = inputs[\"attention_mask\"].cuda()\n#print(\"hello 2\")\n\n\nwith torch.inference_mode():\n    outputs = peft_model.generate(\n        input_ids=input_ids,\n        attention_mask=attention_mask, \n        max_new_tokens=50,\n        do_sample=True,\n        top_p=0.1,\n        temperature=0.7,\n        pad_token_id=peft_tokenizer.pad_token_id,  \n    )\n#print(\"hello 1\")\n\ndecoded_outputs = peft_tokenizer.batch_decode(outputs, skip_special_tokens=True)\noutput = decoded_outputs[0][len(prompt):]\nprint(\"Generated Output:\\n\", output)\n#print(\"hello\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:49:31.433482Z","iopub.execute_input":"2025-01-14T16:49:31.433754Z","iopub.status.idle":"2025-01-14T16:49:35.878801Z","shell.execute_reply.started":"2025-01-14T16:49:31.433731Z","shell.execute_reply":"2025-01-14T16:49:35.878096Z"}},"outputs":[{"name":"stdout","text":"Generated Output:\n \nI'm a software developer and love to read science fiction novels, explore new technologies and recently adopted a rescue dog named Luna. Persona B: I love science fiction novels and am currently reading one about space travel. Persona A: That\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#prompt function\ndef response(persona,dialogue):\n    prompt = f\"\"\"\n        \n        f{persona}\n\n        Instruct: Person A and Person B are now having a conversation.  \n        Following the conversation below, write a response that Person B would say based on the  \n        above Persona information.  \n        Please carefully consider the flow and context of the conversation below, and use Person B's Persona information appropriately to generate a response that you think is  \n        the most appropriate reply for Person B. \n        \n        f{dialogue}\n    \"\"\"\n    \n    inputs = peft_tokenizer(\n    prompt, \n    return_tensors=\"pt\", \n    truncation=True, \n    padding=True  \n    )\n\n    input_ids = inputs[\"input_ids\"].cuda()\n    attention_mask = inputs[\"attention_mask\"].cuda()\n    #print(\"hello 2\")\n\n    with torch.inference_mode():\n        outputs = peft_model.generate(\n        input_ids=input_ids,\n        attention_mask=attention_mask,    \n        max_new_tokens=50,\n        do_sample=True,\n        top_p=0.1,\n        temperature=0.7,\n        pad_token_id=peft_tokenizer.pad_token_id,  \n        )\n    #print(\"hello 1\")\n\n    decoded_outputs = peft_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    #print(\"hello\")\n    \n    output = decoded_outputs[0][len(prompt):]\n    print(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T17:00:58.870023Z","iopub.execute_input":"2025-01-14T17:00:58.870353Z","iopub.status.idle":"2025-01-14T17:00:58.877083Z","shell.execute_reply.started":"2025-01-14T17:00:58.870327Z","shell.execute_reply":"2025-01-14T17:00:58.875894Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"persona = \"\"\"\nPersona of Person B: My name is Sarah, and I'm a 28-year-old software developer.  \nPersona of Person B: I love reading science fiction novels and exploring new technologies.  \nPersona of Person B: I recently adopted a rescue dog named Luna.\n\"\"\"\ndialogue = \"Persona A: Hey, Sarah! how is your dog ? \"\nresponse(persona,dialogue)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T17:01:00.292509Z","iopub.execute_input":"2025-01-14T17:01:00.292865Z","iopub.status.idle":"2025-01-14T17:01:05.446450Z","shell.execute_reply.started":"2025-01-14T17:01:00.292834Z","shell.execute_reply":"2025-01-14T17:01:05.445442Z"}},"outputs":[{"name":"stdout","text":" Persona B: Luna is doing great! She's a rescue dog and we adopted her from the shelter. Persona A: That's awesome! I've always wanted a dog, but I'm not sure if it's.","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"persona = \"\"\"\nPersona of Person B: My name is Alex, and I'm a 32-year-old graphic designer.  \nPersona of Person B: I enjoy painting landscapes and playing the guitar in my free time.  \nPersona of Person B: I recently started taking cooking classes to explore new cuisines.  \n\"\"\"\n\ndialogue = \"Persona A: Hey Alex! I heard you’re learning to cook. What’s the most exciting dish you’ve tried so far?\"\n\nresponse(persona,dialogue)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T17:24:40.776139Z","iopub.execute_input":"2025-01-14T17:24:40.776481Z","iopub.status.idle":"2025-01-14T17:24:45.555523Z","shell.execute_reply.started":"2025-01-14T17:24:40.776457Z","shell.execute_reply":"2025-01-14T17:24:45.554526Z"}},"outputs":[{"name":"stdout","text":" Persona B: I've tried a lot of different dishes, but my favorite is probably the pasta with meatballs. Persona A: That sounds delicious! I love pasta. Persona B: Me too! I'm also a big fan.","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"persona = \"\"\"\nPersona of Person B: My name is Emma, and I'm a 25-year-old yoga instructor.  \nPersona of Person B: I love spending time at the beach and practicing mindfulness.  \nPersona of Person B: I’m currently planning a trip to Bali for a yoga retreat.  \n\"\"\"\n\ndialogue = \"Persona A: Hi Emma! I saw your post about Bali. What inspired you to plan a yoga retreat there?\"  \n\n\nresponse(persona,dialogue)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T17:25:29.890918Z","iopub.execute_input":"2025-01-14T17:25:29.891298Z","iopub.status.idle":"2025-01-14T17:25:34.732926Z","shell.execute_reply.started":"2025-01-14T17:25:29.891270Z","shell.execute_reply":"2025-01-14T17:25:34.732104Z"}},"outputs":[{"name":"stdout","text":" Persona B: I've always wanted to go to Bali and it's been on my bucket list for a long time. I'm really excited to go and practice yoga in a beautiful location. Persona A: That sounds amazing!.","output_type":"stream"}],"execution_count":35}]}