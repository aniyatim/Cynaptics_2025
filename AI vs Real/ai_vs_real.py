# -*- coding: utf-8 -*-
"""AI_vs_Real.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pLw5X0syttg8X13wvlojts7RvUSpwCbb
"""

! pip install -q kaggle

from google.colab import files

files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets list

!kaggle competitions download -c induction-task

! mkdir train
! unzip induction-task.zip -d train

!pip install keras-preprocessing

from keras.utils import to_categorical
from keras_preprocessing.image import load_img
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D
import os
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import numpy as np
from tqdm.notebook import tqdm
from sklearn.model_selection import train_test_split

def createdataframe(dir):
    image_paths = []
    labels = []
    for label in os.listdir(dir):
        for imagename in os.listdir(os.path.join(dir, label)):
            image_paths.append(os.path.join(dir, label, imagename))
            labels.append(label)
        print(label, "completed")
    return image_paths, labels

def extract_features(images):
    features = []
    for image in tqdm(images):
        img = load_img(image, target_size=(236, 236))
        img = np.array(img)
        features.append(img)
    features = np.array(features)
    features = features.reshape(features.shape[0], 236, 236, 3)
    return features

TRAIN_DIR = "/content/train/Data/Train"

train = pd.DataFrame()
train['image'], train['label'] = createdataframe(TRAIN_DIR)

train_features = extract_features(train['image'])

x_train = train_features / 255.0

le = LabelEncoder()
le.fit(train['label'])
y_train = le.transform(train['label'])
y_train = to_categorical(y_train, num_classes=2)

x_train, x_val, y_train, y_val = train_test_split(
    x_train, y_train, test_size=0.2, random_state=42, stratify=y_train
)

model = Sequential()

model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(236, 236, 3)))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

#model.add(Conv2D(1024, kernel_size=(3, 3), activation='relu'))
#model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())

model.add(Dense(64, activation='relu'))
model.add(Dropout(0.3))

model.add(Dense(128, activation='relu'))
model.add(Dropout(0.4))

#model.add(Dense(256, activation='relu'))
#model.add(Dropout(0.3))

#model.add(Dense(512, activation='relu'))
#model.add(Dropout(0.3))

# Output layer
model.add(Dense(2, activation='softmax'))

from keras.optimizers import Adam
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

from keras.callbacks import EarlyStopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
history = model.fit(
    x=x_train,
    y=y_train,
    validation_data=(x_val, y_val),
    batch_size=16,
    epochs=25,
    callbacks=[early_stopping]
)


#history = model.fit(
#    x=x_train,
#    y=y_train,
#    validation_data=(x_val, y_val),
#    batch_size=16,
#    epochs=20
#)

import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

model.save("model_aivsreal.h5")

!kaggle competitions download -c induction-task-2025

! mkdir train2
! unzip induction-task-2025.zip -d train2

import pandas as pd
import numpy as np
from keras.preprocessing.image import load_img

TEST_DIR = "/content/train2/Test_Images"

def create_test_dataframe(dir):
    image_paths = []
    for imagename in os.listdir(dir):
        image_paths.append(os.path.join(dir, imagename))
    return image_paths

def extract_test_features(images):
    features = []
    for image in tqdm(images):
        img = load_img(image, target_size=(236, 236))
        img = np.array(img)
        features.append(img)
    features = np.array(features)
    features = features.reshape(len(features), 236, 236, 3)
    return features

test = pd.DataFrame()
test['image'] = create_test_dataframe(TEST_DIR)
test_features = extract_test_features(test['image'])
x_test = test_features / 255.0

predictions = model.predict(x_test)
predicted_labels = np.argmax(predictions, axis=1)
predicted_labels = le.inverse_transform(predicted_labels)

image_ids = [img.split('/')[-1] for img in test['image']]

results = pd.DataFrame({'Id': image_ids, 'Label': predicted_labels})
results.to_csv('submission.csv', index=False)

# prompt: '/content/train/Data/Test/.ipynb_checkpoints' remove

import shutil
import os

# Define the directory to remove
dir_to_remove = '/content/train/Data/Test/.ipynb_checkpoints'

# Check if the directory exists
if os.path.exists(dir_to_remove):
    try:
        # Use shutil.rmtree to remove the directory and its contents
        shutil.rmtree(dir_to_remove)
        print(f"Directory '{dir_to_remove}' and its contents removed successfully.")
    except OSError as e:
        print(f"Error removing directory '{dir_to_remove}': {e}")
else:
    print(f"Directory '{dir_to_remove}' does not exist.")
